Multiclass classification refers to classification problems where you can have more than just two possible output labels so not just 0 or 1. 

For the handwritten digit classification problems we've looked at so far, we were just trying to distinguish between the handwritten digits 0 and 1. But if you're trying to read protocols or zip codes in an envelope, well, there are actually 10 possible digits you might want to recognize. Or alternatively the example try to classify whether patients may have any of three or five different possible diseases. That too would be a multiclass classification problem.
So a multiclass classification problem is still a classification problem in that y you can take on only a small number of discrete categories is not any number, but now y can take on more than just two possible values. 
So whereas previously for buying the classification, you may have had a data set like this with features x1 and x2. In which case logistic regression would fit model to estimate what the probability of y being 1, given the features x. Because y was either 01 with multiclass classification problems, you would instead have a data set that maybe looks like this. Where we have four classes where the Os represents one class, the xs represent another class. The triangles represent the third class and the squares represent the fourth class. 

And instead of just estimating the chance of y being equal to 1, well, now want to estimate what's the chance that y is equal to 1, or what's the chance that y is equal to 2? Or what's the chance that y is equal to 3, or the chance of y being equal to 4? And it turns out that a algorithm can learn a decision boundary that divides the space exploded next to into four categories rather than just two categories.